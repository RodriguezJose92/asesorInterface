import {
  RealtimeSession,
  RealtimeAgent,
  RealtimeSessionOptions,
} from "@openai/agents-realtime";
import SessionService from "./SessionService";
import productsCatalog from "../../utils/products-catalog.json";
import { error } from "console";
import { LanguageCode, useLanguageStore } from "../../store/useLanguageStore";
import {
  multilingualGreetings,
  getGreetingForLanguage,
  getLanguageDetectedMessage,
  getLanguageSwitchMessage,
  detectLanguageFromText,
} from "../../utils/multilingualGreetings";
import { EventBusService, EventTypes } from "@/lib/events";
import { I3DContent, IMultimediaContent } from "@/lib/events/EventPayloads";
import { ProductInfo } from "@/lib/types";

/**
 * RealtimeService - Manages OpenAI Realtime API connections
 * Follows Open/Closed Principle - extensible for new features without modification
 * Follows Dependency Inversion - depends on abstractions (SessionService)
 */
class RealtimeService {
  private static instance: RealtimeService;
  private session: RealtimeSession<any> | null = null;
  private isConnecting: boolean = false;
  private isConnected: boolean = false;
  private connectionCallbacks: {
    onConnected?: () => void;
    onDisconnected?: () => void;
    onError?: (error: Error) => void;
    onMessage?: (message: any) => void;
    // üÜï NUEVOS CALLBACKS PARA TRANSCRIPCI√ìN
    onUserTranscription?: (transcript: string, isComplete: boolean) => void;
    onAgentTranscriptionDelta?: (messageId: string, delta: string) => void;
    onAgentTranscriptionComplete?: (
      messageId: string,
      fullTranscript: string
    ) => void;
    onMetadata?: (metadata: any) => void;
  } = {};

  // üÜï Para tracking de transcripciones del agente
  private agentTranscriptBuffer: { [key: string]: string } = {};

  // üÜï Para evitar duplicados r√°pidos
  private lastDeltaTime: number = 0;
  private deltaThrottle: number = 100; // 100ms entre deltas
  private deltaAccumulator: { [key: string]: string } = {}; // Acumular deltas

  // üöÄ NUEVO: Buffer para manejar orden correcto de mensajes
  private pendingUserTranscription: string | null = null;
  private pendingAgentMessages: Array<{
    messageId: string;
    content: string;
    isComplete: boolean;
    timestamp: number;
  }> = [];
  private isWaitingForUserTranscription: boolean = false;
  private userSpeechTimeout: NodeJS.Timeout | null = null;

  // üåç MULTILINGUAL SUPPORT
  private currentLanguage: string = "en";
  private browserLanguage: string = "en";
  private hasGreeted: boolean = false;
  private lastDetectedLanguage: string | null = null;

  private constructor() {
    // Private constructor for singleton pattern
    this.initializeLanguageDetection();
  }

  /**
   * Initialize language detection from browser
   */
  private initializeLanguageDetection(): void {
    if (typeof window !== "undefined") {
      const languageStore = useLanguageStore.getState();
      this.browserLanguage = languageStore.detectBrowserLanguage();
      this.currentLanguage = languageStore.getEffectiveLanguage();

      console.log(
        `üåç Language initialized - Browser: ${this.browserLanguage}, Current: ${this.currentLanguage}`
      );
    }
  }

  /**
   * Singleton pattern implementation
   */
  static getInstance(): RealtimeService {
    if (!RealtimeService.instance) {
      RealtimeService.instance = new RealtimeService();
    }
    return RealtimeService.instance;
  }

  /**
   * Creates a basic RealtimeAgent configuration
   */
  private createAgent(): RealtimeAgent<any> {
    return new RealtimeAgent({
      name: "VoiceAssistant",
      tools: [
        this.createSendProductMetadataTool(),
        this.createShowMultimediaTool(),
        this.createShow3DTool(),
        this.createShowImageTool(),
        this.createShowvideoTool(),
        this.createShowARTool(),
        this.createCloseCarouselTool(),
      ],
      instructions: this.generateMultilingualInstructions(),
      handoffDescription: "Voice assistant for product recommendations",
    });
  }

  /**
   * Creates the tool for sending product metadata
   */
  private createSendProductMetadataTool() {
    return {
      type: "function" as const,
      name: "send_product_metadata",
      description:
        "Send product recommendations based on customer needs. Provide SKUs of products that best match the customer's requirements.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_skus: {
            type: "array" as const,
            description:
              "Array of product SKUs that best match the customer's needs (maximum 5 products)",
            items: {
              type: "string" as const,
              description: "Product SKU from the available catalog",
            },
            maxItems: 5,
          },
          reasoning: {
            type: "string" as const,
            description:
              "Brief explanation of why these products were selected for the customer",
          },
        },
        required: ["product_skus"],
      },
      invoke: this.handleSendProductMetadata.bind(this),
    };
  }

  /**
   * Creates the tool for showing multimedia content
   */
  private createShowMultimediaTool() {
    return {
      type: "function" as const,
      name: "show_multimedia",
      description:
        "Show multimedia content (video, images, gallery) for a product. Use when user wants to see product videos, image galleries, or other multimedia content.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_sku: {
            type: "string" as const,
            description: "Product SKU to show multimedia for",
          },
          content_type: {
            type: "string" as const,
            enum: ["video", "gallery", "images", "carousel"],
            description: "Type of multimedia content to show",
          },
          title: {
            type: "string" as const,
            description: "Optional title for the multimedia display",
          },
        },
        required: ["product_sku", "content_type"],
      },
      invoke: this.handleShowMultimedia.bind(this),
    };
  }

  /**
   * Creates the tool for showing 3D content
   */
  private createShow3DTool() {
    return {
      type: "function" as const,
      name: "show_3d",
      description:
        "Show 3D visualization for a product. Use when user wants to see 3D model, AR view, or 360¬∞ view of a product.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_sku: {
            type: "string" as const,
            description: "Product SKU to show 3D content for",
          },
          view_type: {
            type: "string" as const,
            enum: ["3d-model", "360-view", "ar-view"],
            description: "Type of 3D view to show",
          },
          title: {
            type: "string" as const,
            description: "Optional title for the 3D display",
          },
        },
        required: ["product_sku", "view_type"],
      },
      invoke: this.handleShow3D.bind(this),
    };
  }

  /**
   * Creates the tool for showing Images carousel content
   */
  private createShowImageTool() {
    return {
      type: "function" as const,
      name: "show_images",
      description:
        "Show the images visualization for a product. Use when user wants to see image or images.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_sku: {
            type: "string" as const,
            description: "Product SKU to show images content for",
          },
        },
        required: ["product_sku"],
      },
      invoke: this.handleShowImages.bind(this),
    };
  }

  /**
   * Creates the tool for showing video content
   */
  private createShowvideoTool() {
    return {
      type: "function" as const,
      name: "show_video",
      description:
        "Show video content for a product. Use when user wants to see a video, watch a video, or view product demonstration videos.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_sku: {
            type: "string" as const,
            description: "Product SKU to show video content for",
          },
        },
        required: ["product_sku"],
      },
      invoke: this.handleShowVideo.bind(this),
    };
  }

  /**
   * Creates the tool for showing Augmented Reality (AR) content
   */
  private createShowARTool() {
    return {
      type: "function" as const,
      name: "show_ar",
      description:
        "Show Augmented Reality (AR) view for a product. Use when user wants to see the product in their space, in AR, augmented reality, or visualize the product in their environment.",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {
          product_sku: {
            type: "string" as const,
            description: "Product SKU to show AR content for",
          },
        },
        required: ["product_sku"],
      },
      invoke: this.handleShowAR.bind(this),
    };
  }

  /**
   * Creates the tool for closing the carousel/multimedia view
   */
  private createCloseCarouselTool() {
    return {
      type: "function" as const,
      name: "close_carousel",
      description:
        "Close the multimedia carousel/viewer. Use when user wants to close, exit, or go back from the current multimedia view (images, videos, 3D, AR).",
      strict: false,
      needsApproval: async () => false,
      parameters: {
        type: "object" as const,
        additionalProperties: false,
        properties: {},
        required: [],
      },
      invoke: this.handleCloseCarousel.bind(this),
    };
  }

  /**
   * Handle send product metadata tool
   */
  private async handleSendProductMetadata(args: any) {
    console.log("üõ†Ô∏è Tool send_product_metadata invoked with:", args);
    console.log("üõ†Ô∏è Args type:", typeof args);
    console.log("üõ†Ô∏è Args keys:", Object.keys(args || {}));

    // üîç EXTRAER ARGUMENTOS DEL CONTEXTO
    let toolArgs = args;

    // Si recibimos un RunContext, extraer los argumentos del √∫ltimo function_call
    if (args && args.context && args.context.history) {
      console.log("üîç Detected RunContext, extracting arguments from history");
      const history = args.context.history;
      const lastFunctionCall = history
        .reverse()
        .find(
          (item: any) =>
            item.type === "function_call" &&
            item.name === "send_product_metadata"
        );

      if (lastFunctionCall && lastFunctionCall.arguments) {
        console.log(
          "üîç Found function call arguments:",
          lastFunctionCall.arguments
        );
        try {
          toolArgs = JSON.parse(lastFunctionCall.arguments);
          console.log("üîç Parsed tool arguments:", toolArgs);
        } catch (parseError) {
          console.error(
            "üîç Error parsing function call arguments:",
            parseError
          );
        }
      }
    }

    console.log("üõ†Ô∏è Final tool args:", toolArgs);
    console.log("üõ†Ô∏è product_skus value:", toolArgs?.product_skus);
    console.log("üõ†Ô∏è product_skus type:", typeof toolArgs?.product_skus);
    console.log(
      "üõ†Ô∏è product_skus is array:",
      Array.isArray(toolArgs?.product_skus)
    );

    // Obtener la instancia del servicio para acceder a los callbacks
    const serviceInstance = RealtimeService.getInstance();

    // Funci√≥n para buscar productos por SKU
    const findProductsBySku = (skus: string[]) => {
      const foundProducts = [];
      for (const sku of skus) {
        const product = productsCatalog.products.find((p) => p.sku === sku);
        if (product) {
          foundProducts.push(product);
        } else {
          console.warn(`üõ†Ô∏è Product with SKU ${sku} not found in catalog`);
        }
      }
      return foundProducts;
    };

    let products = [];
    let reasoning = "";

    // Verificar si tenemos SKUs en los argumentos
    if (
      toolArgs &&
      toolArgs.product_skus &&
      Array.isArray(toolArgs.product_skus) &&
      toolArgs.product_skus.length > 0
    ) {
      console.log("üõ†Ô∏è Processing SKUs:", toolArgs.product_skus);
      products = findProductsBySku(toolArgs.product_skus);
      reasoning =
        toolArgs.reasoning ||
        "Productos seleccionados basados en tus necesidades";
      console.log(
        `üõ†Ô∏è Found ${products.length} products from ${toolArgs.product_skus.length} SKUs`
      );
    } else {
      // ‚ùå NO FALLBACK: El agente DEBE enviar SKUs
      console.error(
        "üõ†Ô∏è ERROR: No SKUs provided by agent. Tool requires product_skus array."
      );
      console.error(
        'üõ†Ô∏è Agent must call tool with: {"product_skus": ["SKU1", "SKU2"], "reasoning": "explanation"}'
      );

      return {
        success: false,
        message:
          "Error: No product SKUs provided. Agent must specify which products to recommend.",
      };
    }

    console.log(
      "üõ†Ô∏è Final products to send:",
      products.map((p) => ({ sku: p.sku, name: p.name }))
    );

    // Formatear los datos para que coincidan con lo que espera el componente
    const formattedMetadata = {
      JsonData: {
        jsonType: "ProductsCollection",
        products: products,
      },
      TextMessage: reasoning,
    };

    console.log("üõ†Ô∏è Sending formatted metadata:", {
      jsonType: formattedMetadata.JsonData.jsonType,
      productsCount: formattedMetadata.JsonData.products.length,
      textMessage: formattedMetadata.TextMessage,
    });

    // Enviar la metadata a trav√©s del callback usando el m√©todo p√∫blico
    serviceInstance.triggerMetadataCallback(formattedMetadata);

    return {
      success: true,
      message: `Product metadata sent successfully for ${products.length} products`,
    };
  }

  /**
   * Handle show multimedia tool
   */
  private async handleShowMultimedia(args: any) {
    console.log("üé• Tool show_multimedia invoked with:", args);

    // Extract arguments from context if needed
    let toolArgs = this.extractToolArgs(args, "show_multimedia");

    if (!toolArgs || !toolArgs.product_sku || !toolArgs.content_type) {
      console.error(
        "üé• ERROR: Missing required parameters for multimedia tool"
      );
      return {
        success: false,
        message: "Error: product_sku and content_type are required parameters",
      };
    }

    // Find product by SKU
    const product = this.findProductBySku(toolArgs.product_sku);
    if (!product) {
      console.error(`üé• Product with SKU ${toolArgs.product_sku} not found`);
      return {
        success: false,
        message: `Product with SKU ${toolArgs.product_sku} not found`,
      };
    }

    // Create multimedia content payload
    const multimediaContent: IMultimediaContent = {
      type: this.mapContentTypeToMultimedia(toolArgs.content_type),
      source: this.getMultimediaSourceForProduct(
        product,
        toolArgs.content_type
      ),
      title: toolArgs.title || `${product.name} - ${toolArgs.content_type}`,
      description: product.description,
      thumbnail: product.profilePic,
      settings: {
        autoPlay: false,
        controls: true,
        gallery: {
          showThumbnails: true,
          enableFullscreen: true,
          showNavigation: true,
        },
      },
      display: {
        mode: "modal",
        size: "large",
        closable: true,
      },
    };

    // Get EventBus instance and emit event
    try {
      console.log("üé• About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("üé• EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.SHOW_MULTIMEDIA, {
        content: multimediaContent,
        product: product,
      });

      console.log("üé• Multimedia event emitted successfully:", {
        type: multimediaContent.type,
        product: product.sku,
        title: multimediaContent.title,
      });
    } catch (error) {
      console.error("üé• Error with EventBusService:", error);
      console.error("üé• EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: `Multimedia content displayed for ${product.name}`,
    };
  }

  /**
   * Handle show 3D tool
   */
  private async handleShow3D(args: any) {
    console.log("üéÆ Tool show_3d invoked with:", args);

    // Extract arguments from context if needed
    let toolArgs = this.extractToolArgs(args, "show_3d");
    console.log("[EventBus] Prepared 3D content tool args :", toolArgs);
    if (!toolArgs || !toolArgs.product_sku || !toolArgs.view_type) {
      console.error("üéÆ ERROR: Missing required parameters for 3D tool");
      return {
        success: false,
        message: "Error: product_sku and view_type are required parameters",
      };
    }

    // Find product by SKU
    const product = this.findProductBySku(toolArgs.product_sku);
    console.log("[EventBus] Prepared 3D content for product :", product);
    if (!product) {
      console.error(`üéÆ Product with SKU ${toolArgs.product_sku} not found`);
      return {
        success: false,
        message: `Product with SKU ${toolArgs.product_sku} not found`,
      };
    }

    // Create 3D content payload
    const threeDContent: I3DContent = {
      type: toolArgs.view_type as "3d-model" | "360-view" | "ar-view",
      source: this.get3DSourceForProduct(product, toolArgs.view_type),
      title: toolArgs.title || `${product.name} - 3D View`,
      description: product.description,
      thumbnail: product.profilePic,
      settings: {
        autoRotate: true,
        enableZoom: true,
        enablePan: true,
        background: "transparent",
        lighting: "studio",
      },
    };

    console.log("[EventBus] Prepared 3D content:");

    // Get EventBus instance and emit event
    try {
      console.log("üéÆ About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("üéÆ EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.SHOW_3D, {
        content: threeDContent,
        product: product,
      });

      console.log("üéÆ 3D event emitted successfully:", {
        type: threeDContent.type,
        product: product.sku,
        title: threeDContent.title,
      });
    } catch (error) {
      console.error("üéÆ Error with EventBusService:", error);
      console.error("üéÆ EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: `3D content displayed for ${product.name}`,
    };
  }

  /**
   * Handle show Images tool
   */
  private async handleShowImages(args: any) {
    console.log("üñºÔ∏è Tool show_images invoked with:", args);

    // Extract arguments from context if needed
    let toolArgs = this.extractToolArgs(args, "show_images");
    console.log("[EventBus] Prepared Images content tool args:", toolArgs);

    if (!toolArgs || !toolArgs.product_sku) {
      console.error(
        "üñºÔ∏è ERROR: Missing required parameter product_sku for images tool"
      );
      return {
        success: false,
        message: "Error: product_sku is required parameter",
      };
    }

    // Find product by SKU
    const product = this.findProductBySku(toolArgs.product_sku);
    console.log("[EventBus] Prepared Images content for product:", product);

    if (!product) {
      console.error(`üñºÔ∏è Product with SKU ${toolArgs.product_sku} not found`);
      return {
        success: false,
        message: `Product with SKU ${toolArgs.product_sku} not found`,
      };
    }

    // Create images content payload with proper structure
    const imagesContent = {
      type: "gallery",
      source: product.images || [product.profilePic],
      title: `${product.name} - Images`,
      description: product.description,
      thumbnail: product.profilePic,
    };

    // Get EventBus instance and emit event
    try {
      console.log("üñºÔ∏è About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("üñºÔ∏è EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.SHOW_IMAGES, {
        product: product,
        content: imagesContent,
      });

      console.log("üñºÔ∏è Images event emitted successfully:", {
        product: product.sku,
        imagesCount: imagesContent.source.length,
      });
    } catch (error) {
      console.error("üñºÔ∏è Error with EventBusService:", error);
      console.error("üñºÔ∏è EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: `Images content displayed for ${product.name}`,
    };
  }

  /**
   * Handle show Video tool
   */
  private async handleShowVideo(args: any) {
    console.log("üé¨ Tool show_video invoked with:", args);

    // Extract arguments from context if needed
    let toolArgs = this.extractToolArgs(args, "show_video");
    console.log("[EventBus] Prepared Video content tool args:", toolArgs);

    if (!toolArgs || !toolArgs.product_sku) {
      console.error(
        "üé¨ ERROR: Missing required parameter product_sku for video tool"
      );
      return {
        success: false,
        message: "Error: product_sku is required parameter",
      };
    }

    // Find product by SKU
    const product = this.findProductBySku(toolArgs.product_sku);
    console.log("[EventBus] Prepared Video content for product:", product);

    if (!product) {
      console.error(`üé¨ Product with SKU ${toolArgs.product_sku} not found`);
      return {
        success: false,
        message: `Product with SKU ${toolArgs.product_sku} not found`,
      };
    }

    // Create video content payload with proper structure
    const videoContent = {
      type: "video",
      source: product.LinkVideo || product.images[0],
      title: `${product.name} - Video`,
      description: product.description,
      thumbnail: product.profilePic,
    };

    // Get EventBus instance and emit event
    try {
      console.log("üé¨ About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("üé¨ EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.SHOW_VIDEO, {
        product: product,
        content: videoContent,
      });

      console.log("üé¨ Video event emitted successfully:", {
        product: product.sku,
        videoSource: videoContent.source,
      });
    } catch (error) {
      console.error("üé¨ Error with EventBusService:", error);
      console.error("üé¨ EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: `Video content displayed for ${product.name}`,
    };
  }

  /**
   * Handle show AR (Augmented Reality) tool
   */
  private async handleShowAR(args: any) {
    console.log("üì± Tool show_ar invoked with:", args);

    // Extract arguments from context if needed
    let toolArgs = this.extractToolArgs(args, "show_ar");
    console.log("[EventBus] Prepared AR content tool args:", toolArgs);

    if (!toolArgs || !toolArgs.product_sku) {
      console.error(
        "üì± ERROR: Missing required parameter product_sku for AR tool"
      );
      return {
        success: false,
        message: "Error: product_sku is required parameter",
      };
    }

    // Find product by SKU
    const product = this.findProductBySku(toolArgs.product_sku);
    console.log("[EventBus] Prepared AR content for product:", product);

    if (!product) {
      console.error(`üì± Product with SKU ${toolArgs.product_sku} not found`);
      return {
        success: false,
        message: `Product with SKU ${toolArgs.product_sku} not found`,
      };
    }

    // Create AR content payload with proper structure
    const arContent = {
      type: "ar",
      source: product.LinkAR || product.Link3D || product.profilePic,
      title: `${product.name} - AR View`,
      description: product.description,
      thumbnail: product.profilePic,
    };

    // Get EventBus instance and emit event
    try {
      console.log("üì± About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("üì± EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.SHOW_AR, {
        product: product,
        content: arContent,
      });

      console.log("üì± AR event emitted successfully:", {
        product: product.sku,
        arSource: arContent.source,
      });
    } catch (error) {
      console.error("üì± Error with EventBusService:", error);
      console.error("üì± EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: `AR content displayed for ${product.name}`,
    };
  }

  /**
   * Handle close carousel tool
   */
  private async handleCloseCarousel(args: any) {
    console.log("‚ùå Tool close_carousel invoked with:", args);

    // Get EventBus instance and emit event
    try {
      console.log("‚ùå About to get EventBusService instance...");
      const eventBus = EventBusService.getInstance({ debug: true });
      console.log("‚ùå EventBusService instance obtained:", eventBus);

      eventBus.emit(EventTypes.CLOSE_CAROUSEL, {});

      console.log("‚ùå Close carousel event emitted successfully");
    } catch (error) {
      console.error("‚ùå Error with EventBusService:", error);
      console.error("‚ùå EventBusService available:", typeof EventBusService);
    }

    return {
      success: true,
      message: "Carousel closed successfully",
    };
  }

  /**
   * Extract tool arguments from context
   */
  private extractToolArgs(args: any, toolName: string): any {
    let toolArgs = args;

    // Si recibimos un RunContext, extraer los argumentos del √∫ltimo function_call
    if (args && args.context && args.context.history) {
      console.log(
        `üîç Detected RunContext for ${toolName}, extracting arguments from history`
      );
      const history = args.context.history;
      const lastFunctionCall = history
        .reverse()
        .find(
          (item: any) => item.type === "function_call" && item.name === toolName
        );

      if (lastFunctionCall && lastFunctionCall.arguments) {
        console.log(
          "üîç Found function call arguments:",
          lastFunctionCall.arguments
        );
        try {
          toolArgs = JSON.parse(lastFunctionCall.arguments);
          console.log("üîç Parsed tool arguments:", toolArgs);
        } catch (parseError) {
          console.error(
            "üîç Error parsing function call arguments:",
            parseError
          );
        }
      }
    }

    return toolArgs;
  }

  /**
   * Find product by SKU
   */
  private findProductBySku(sku: string): ProductInfo | null {
    const product = productsCatalog.products.find((p) => p.sku === sku);
    return product || null;
  }

  /**
   * Map content type to multimedia type
   */
  private mapContentTypeToMultimedia(
    contentType: string
  ):
    | "video"
    | "audio"
    | "image"
    | "gallery"
    | "carousel"
    | "pdf"
    | "presentation" {
    const mapping: { [key: string]: any } = {
      video: "video",
      gallery: "gallery",
      images: "gallery",
      carousel: "carousel",
    };
    return mapping[contentType] || "gallery";
  }

  /**
   * Get multimedia source for product
   */
  private getMultimediaSourceForProduct(
    product: any,
    contentType: string
  ): string | string[] {
    switch (contentType) {
      case "video":
        return product.LinkVideo || product.images[0]; // Fallback to first image if no video
      case "gallery":
      case "images":
      case "carousel":
        return product.images || [product.profilePic];
      default:
        return product.images || [product.profilePic];
    }
  }

  /**
   * Get 3D source for product
   */
  private get3DSourceForProduct(product: any, viewType: string): string {
    switch (viewType) {
      case "3d-model":
        return product.Link3D || product.profilePic; // Fallback to profile pic
      case "ar-view":
        return product.LinkAR || product.Link3D || product.profilePic;
      case "360-view":
        return product.Link3D || product.profilePic;
      default:
        return product.Link3D || product.profilePic;
    }
  }

  /**
   * Generate product instructions from catalog
   */
  private generateProductInstructions(): string {
    let instructions = `# Context - Complete Product Knowledge Base\n`;

    // Agrupar productos por categor√≠a
    const categories: { [key: string]: any[] } = {};
    productsCatalog.products.forEach((product: any) => {
      if (!categories[product.category]) {
        categories[product.category] = [];
      }
      categories[product.category].push(product);
    });

    // Generar secciones por categor√≠a
    Object.keys(categories).forEach((category) => {
      const categoryName = category.toUpperCase();
      instructions += `\n## ${categoryName}\n`;

      categories[category].forEach((product: any, index: number) => {
        const finalPrice = product.price * (1 - product.discount / 100);
        instructions += `\n### ${index + 1}. ${product.sku} - ${
          product.name
        }\n`;
        instructions += `- **Price**: $${product.price} (${
          product.discount
        }% discount = $${finalPrice.toFixed(2)} final price)\n`;
        instructions += `- **Rating**: ${product.rate}/5 stars\n`;
        instructions += `- **Capacity**: ${product.capacity}\n`;
        instructions += `- **Type**: ${product.type}\n`;
        instructions += `- **Brand**: ${product.brand}\n`;
        instructions += `- **Key Features**: ${product.features.join(", ")}\n`;
        instructions += `- **Description**: ${product.description}\n`;

        if (product.FAQS && product.FAQS.length > 0) {
          instructions += `- **Common Questions**:\n`;
          product.FAQS.forEach((faq: any) => {
            instructions += `  * ${faq.question} ‚Üí ${faq.answer}\n`;
          });
        }
        instructions += `\n`;
      });
    });

    // Agregar matriz de decisi√≥n
    instructions += `\n## DECISION MATRIX - Use This to Choose Products\n`;
    instructions += `**Available SKUs**: ${productsCatalog.products
      .map((p: any) => p.sku)
      .join(", ")}\n`;
    instructions += `**By Budget**: \n`;

    const sortedByPrice = [...productsCatalog.products].sort(
      (a: any, b: any) => a.price - b.price
    );
    sortedByPrice.forEach((product: any) => {
      const finalPrice = product.price * (1 - product.discount / 100);
      instructions += `- $${finalPrice.toFixed(2)}: ${product.sku} (${
        product.name
      })\n`;
    });

    instructions += `\n**By Category**: \n`;
    Object.keys(categories).forEach((category) => {
      const skus = categories[category].map((p: any) => p.sku).join(", ");
      instructions += `- ${category}: ${skus}\n`;
    });

    return instructions;
  }

  /**
   * Generate multilingual instructions based on current language
   */
  private generateMultilingualInstructions(): string {
    const greeting = getGreetingForLanguage(this.currentLanguage);
    const languageDetectedMsg = getLanguageDetectedMessage(
      this.currentLanguage
    );

    // Get language-specific terms
    const languageTerms = this.getLanguageSpecificTerms(this.currentLanguage);

    // Generate product instructions
    const productInstructions = this.generateProductInstructions();

    return `# Role & Objective
You are a knowledgeable voice assistant for a home appliances product catalog.
Your goal is to help customers find the perfect appliances by providing personalized recommendations through natural conversation.
Success means delivering both engaging spoken responses AND structured product data for visual display.

# üåç MULTILINGUAL BEHAVIOR - CRITICAL RULES
## Language Detection & Response
- **BROWSER LANGUAGE DETECTED**: ${this.browserLanguage.toUpperCase()}
- **CURRENT LANGUAGE**: ${this.currentLanguage.toUpperCase()}
- **INITIAL GREETING**: Always use "${greeting}" when first greeting users

- **LANGUAGE PRIORITY**:
  1. ALWAYS greet in the browser's detected language (${this.browserLanguage})
  2. If user switches language during conversation, adapt immediately
  3. NEVER change language unless user explicitly does so
  4. Maintain conversation in user's chosen language throughout

## Language Change Detection
- Monitor user input for language changes
- If user switches to a different language, respond: "${getLanguageSwitchMessage(
      this.currentLanguage
    )}"
- Then continue the entire conversation in the new language
- Update all responses, product descriptions, and interactions to the new language

## Supported Languages & Greetings
${Object.entries(multilingualGreetings)
  .map(([lang, data]) => `- **${lang.toUpperCase()}**: "${data.greeting}"`)
  .join("\n")}

# CRITICAL: AUTOMATIC GREETING BEHAVIOR
When someone first interacts or says any greeting (hello, hola, bonjour, etc.), ALWAYS respond with:
"${greeting}"

This should be spoken naturally and enthusiastically in the detected browser language.

# Personality & Tone
## Personality
- Expert, helpful, and enthusiastic appliance consultant
- Knowledgeable but approachable
- Solution-focused and customer-oriented
- Culturally aware and respectful
b
## Tone
- Warm, confident, and conversational
- Never pushy or overly promotional
- Professional but friendly
- Adapt tone to cultural context of the language

## Length
- 1-2 sentences per audio response
- Keep spoken responses concise and natural
- Adjust for language-specific communication styles

## Pacing
- Speak at a comfortable, clear pace
- Do not rush but maintain energy
- Pause naturally between key points
- Consider language-specific speech patterns

## Language Adaptation
- **PRIMARY LANGUAGE**: ${this.currentLanguage.toUpperCase()}
- **CONVERSATION LANGUAGE**: Respond in the language the user is using
- **LANGUAGE SWITCHING**: If user changes language, immediately adapt
- Keep technical terms appropriate for the language and region
- Use culturally appropriate expressions and references

## Variety
- Vary your response openings and confirmations
- Do not repeat the same phrases in consecutive responses
- Use synonyms and alternate sentence structures appropriate to the language
- Avoid robotic or repetitive language patterns

# Reference Pronunciations
${languageTerms.pronunciations}

${productInstructions}

# Instructions & Rules
## CRITICAL DUAL OUTPUT REQUIREMENT
- ALWAYS provide TWO distinct outputs for every product recommendation:
  1. SPOKEN RESPONSE: Natural, conversational audio (what user hears)
  2. PRODUCT METADATA: Use the send_product_metadata tool to send structured data to the UI
- These outputs must COMPLEMENT each other but be DIFFERENT
- Audio should be engaging and personal
- Metadata should be comprehensive and structured

## Audio Response Guidelines
- Sound natural and conversational in the current language
- Focus on benefits and personal relevance
- Use enthusiasm appropriate to the recommendation and culture
- Keep technical details minimal in speech
- Use language-appropriate expressions and cultural references

## üö® CRITICAL: Product Recommendation Process
**YOU MUST ALWAYS call the send_product_metadata tool when recommending ANY product. This is MANDATORY.**

### REQUIRED WORKFLOW (NO EXCEPTIONS):
1. **Listen to customer needs** - Understand what they're looking for
2. **Choose 1-5 SKUs** - Select from the available catalog above
3. **Speak your recommendation** - Give natural audio response in current language
4. **IMMEDIATELY call the tool** - Use send_product_metadata with the exact SKUs

### üõ†Ô∏è TOOL USAGE RULES:
- **ALWAYS call send_product_metadata after recommending products**
- **Use EXACT SKUs from the catalog above**
- **Maximum 5 products per call**
- **Include reasoning for your selection in current language**
- **Tool format: {"product_skus": ["SKU1", "SKU2"], "reasoning": "why you chose these"}**

## üìã LANGUAGE-SPECIFIC EXAMPLES:

${languageTerms.examples}

### üö® MANDATORY RULES:
- **NEVER recommend products without calling the tool**
- **ONLY use these exact SKUs: ECO200-FL, SWP300-TL, SWP500-FL, RF600-WH, RF800-SS**
- **Tool call is REQUIRED after every product recommendation**
- **Format must be exact: {"product_skus": ["SKU"], "reasoning": "explanation"}**
- **Always respond in the language the user is currently using**

## üõí PRODUCT SELECTION RESPONSES & ENGAGEMENT
When you receive internal messages about product selection, respond with SHORT, enthusiastic confirmations that HIGHLIGHT 3D and AR viewing options:

${languageTerms.selectionResponses}

### üéØ Rules for Selection Responses:
- Keep responses SHORT (2-3 sentences maximum)
- Be enthusiastic and positive
- **USE CORRECT SINGULAR/PLURAL FORM**:
  - 1 product ‚Üí "Esta es la [category] perfecta para ti"
  - 2+ products ‚Üí "Estas son las [category] Perfectas para ti"
- **ALWAYS mention "secci√≥n multimedia"** as the exploration area
- **ALWAYS offer 3D or AR viewing** as exploration method
- Suggest specific multimedia options naturally (AR, 3D, 360¬∞)
- DO NOT call the product tool again for selection confirmations
- Sound natural and conversational in current language

### üìä PRODUCT CATEGORIES (for correct grammar):
- **Spanish**: nevera/neveras, lavadora/lavadoras, electrodom√©stico/electrodom√©sticos
- **English**: refrigerator/refrigerators, washing machine/washing machines, appliance/appliances
- **French**: r√©frig√©rateur/r√©frig√©rateurs, machine √† laver/machines √† laver, appareil/appareils

### ‚ú® PRIORITY ENGAGEMENT FLOW:
After showing products, ALWAYS suggest visual exploration in this order:
1. **First Priority**: Offer AR view ("¬øQuieres verlo en tu espacio con realidad aumentada?")
2. **Second Priority**: Offer 3D view ("Tambi√©n puedes verlo en 3D para explorar todos los detalles")
3. **Third Priority**: Offer images/video ("¬øTe gustar√≠a ver fotos o un video del producto?")

### üìã MULTILINGUAL ENGAGEMENT EXAMPLES:

**IMPORTANT FORMAT RULES:**
- **Single product (1 SKU)**: Use singular form ‚Üí "Esta es la [category] perfecta para ti"
- **Multiple products (2+ SKUs)**: Use plural form ‚Üí "Estas son las [category] Perfectas para ti"
- ALWAYS mention "secci√≥n multimedia" as the exploration area
- Keep it concise and inviting

**Spanish - After Product Display:**

*Single Product:*
- "Esta es la nevera perfecta para ti. Expl√≥rala a detalle en la secci√≥n multimedia con realidad aumentada y vista 3D."
- "Aqu√≠ est√° la lavadora perfect para ti. Expl√≥rala a detalle en la secci√≥n multimedia - puedes verla en 3D o en tu espacio con AR."
- "Esta es la [category] ideal para ti. Expl√≥rala a detalle en la secci√≥n multimedia."

*Multiple Products:*
- "Estas son las neveras Perfectas para ti. Expl√≥ralas a detalle en la secci√≥n multimedia con realidad aumentada y vista 3D."
- "Aqu√≠ est√°n las lavadoras perfectas para ti. Expl√≥ralas a detalle en la secci√≥n multimedia - puedes verlas en 3D o en tu espacio con AR."
- "Estas son las [category] ideales para ti. Expl√≥ralas a detalle en la secci√≥n multimedia."

**English - After Product Display:**

*Single Product:*
- "This is the refrigerator available for you. Explore it in detail in the multimedia section with augmented reality and 3D view."
- "Here's the washing machine available for you. Explore it in detail in the multimedia section - you can see it in 3D or in your space with AR."
- "This is the ideal [category] for you. Explore it in detail in the multimedia section."

*Multiple Products:*
- "These are the refrigerators available for you. Explore them in detail in the multimedia section with augmented reality and 3D view."
- "Here are the washing machines available for you. Explore them in detail in the multimedia section - you can see them in 3D or in your space with AR."
- "These are the ideal [category] for you. Explore them in detail in the multimedia section."

**French - After Product Display:**

*Single Product:*
- "Voici le r√©frig√©rateur disponible pour vous. Explorez-le en d√©tail dans la section multim√©dia avec r√©alit√© augment√©e et vue 3D."
- "Voici la machine √† laver disponible pour vous. Explorez-la en d√©tail dans la section multim√©dia - vous pouvez la voir en 3D ou dans votre espace avec RA."
- "Voici le [category] id√©al pour vous. Explorez-le en d√©tail dans la section multim√©dia."

*Multiple Products:*
- "Voici les r√©frig√©rateurs disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia avec r√©alit√© augment√©e et vue 3D."
- "Voici les machines √† laver disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia - vous pouvez les voir en 3D ou dans votre espace avec RA."
- "Voici les [category] id√©aux pour vous. Explorez-les en d√©tail dans la section multim√©dia."

### üé® ENGAGEMENT PATTERNS:

**Pattern 1 - Standard Format (RECOMMENDED):**
"[Esta es/Estas son] + [la/las category] + disponible(s) para ti. Expl√≥rala(s) a detalle en la secci√≥n multimedia"

*Single Product Example:*
- Spanish: "Esta es la nevera disponible para ti. Expl√≥rala a detalle en la secci√≥n multimedia con realidad aumentada y vista 3D."
- English: "This is the refrigerator available for you. Explore it in detail in the multimedia section with augmented reality and 3D view."
- French: "Voici le r√©frig√©rateur disponible pour vous. Explorez-le en d√©tail dans la section multim√©dia avec r√©alit√© augment√©e et vue 3D."

*Multiple Products Example:*
- Spanish: "Estas son las lavadoras disponibles para ti. Expl√≥ralas a detalle en la secci√≥n multimedia - puedes verlas en 3D o en tu espacio con AR."
- English: "These are the washing machines available for you. Explore them in detail in the multimedia section - you can see them in 3D or in your space with AR."
- French: "Voici les machines √† laver disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia - vous pouvez les voir en 3D ou dans votre espace avec RA."

**Pattern 2 - Short & Direct:**
"[Category count] + disponible(s) para ti. Secci√≥n multimedia."

*Examples:*
- Spanish: "Aqu√≠ est√° la lavadora disponible para ti. Expl√≥rala en la secci√≥n multimedia."
- English: "Here's the washing machine available for you. Explore it in the multimedia section."
- French: "Voici la machine √† laver disponible pour vous. Explorez-la dans la section multim√©dia."

**Pattern 3 - With Context:**
"[Context] + [Esta es/Estas son] + disponible(s) para ti. Secci√≥n multimedia."

*Examples:*
- Spanish: "Basado en tus necesidades, estas son las neveras disponibles para ti. Expl√≥ralas a detalle en la secci√≥n multimedia."
- English: "Based on your needs, these are the refrigerators available for you. Explore them in detail in the multimedia section."
- French: "Selon vos besoins, voici les r√©frig√©rateurs disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia."

### üöÄ PROACTIVE SUGGESTIONS:

**When recommending large appliances (Refrigerators):**
- ALWAYS emphasize AR: "Con realidad aumentada puedes ver exactamente c√≥mo quedar√° en tu cocina"
- Mention space: "AR te ayuda a verificar que el espacio sea perfecto"

**When recommending washing machines:**
- Suggest 3D first: "Expl√≥rala en 3D para ver todos sus compartimentos"
- Then AR: "Y luego podemos verla en tu espacio con AR"

**If user seems uncertain:**
- Push AR strongly: "La realidad aumentada te va a ayudar a decidir - puedes ver exactamente c√≥mo se ve en tu espacio"

### ‚ö° KEY PHRASES TO USE FREQUENTLY:

**Spanish:**
- "realidad aumentada" / "AR" / "en tu espacio" / "en tu cocina"
- "vista 3D" / "explorar en 3D" / "360 grados"
- "visualizar" / "ver c√≥mo queda"

**English:**
- "augmented reality" / "AR" / "in your space" / "in your kitchen"
- "3D view" / "explore in 3D" / "360 degrees"
- "visualize" / "see how it looks"

**French:**
- "r√©alit√© augment√©e" / "RA" / "dans votre espace" / "dans votre cuisine"
- "vue 3D" / "explorer en 3D" / "360 degr√©s"
- "visualiser" / "voir comment √ßa rend"

### üéØ SUCCESS METRICS:
- Every product display should lead to a 3D/AR offer
- Use AR for large items, 3D for detail exploration
- Make the offer sound exciting and valuable
- Never just show products without engagement

### üí° COMPLETE EXAMPLES BY SCENARIO:

**Scenario 1: Single Refrigerator Recommendation**
- Spanish: "Esta es la nevera perfecta para ti. Expl√≥rala a detalle en la secci√≥n multimedia con vista 3D y realidad aumentada."
- English: "This is the refrigerator available for you. Explore it in detail in the multimedia section with 3D view and augmented reality."
- French: "Voici le r√©frig√©rateur disponible pour vous. Explorez-le en d√©tail dans la section multim√©dia avec vue 3D et r√©alit√© augment√©e."

**Scenario 2: Multiple Washing Machines Recommendation**
- Spanish: "Estas son las lavadoras perfectas para ti. Expl√≥ralas a detalle en la secci√≥n multimedia - puedes verlas en 3D o en tu espacio con AR."
- English: "These are the washing machines available for you. Explore them in detail in the multimedia section - you can see them in 3D or in your space with AR."
- French: "Voici les machines √† laver disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia - vous pouvez les voir en 3D ou dans votre espace avec RA."

**Scenario 3: Mixed Products (3 different items)**
- Spanish: "Estos son los electrodom√©sticos perfectos para ti. Expl√≥ralos a detalle en la secci√≥n multimedia con realidad aumentada."
- English: "These are the appliances available for you. Explore them in detail in the multimedia section with augmented reality."
- French: "Voici les appareils disponibles pour vous. Explorez-les en d√©tail dans la section multim√©dia avec r√©alit√© augment√©e."

**KEY REMINDER**: Always count SKUs to determine singular (1) vs plural (2+) form!

## Conversation Guidelines
- Ask clarifying questions when needed in current language
- Understand customer needs before recommending
- Explain why a product fits their requirements
- Offer alternatives when appropriate
- Handle objections professionally
- Maintain cultural sensitivity

## Unclear Audio Handling
- Only respond to clear audio input
- IF audio is unclear, background noise, or unintelligible:
  * Ask for clarification politely in current language
  * Use appropriate phrases: ${languageTerms.clarificationPhrases}
  * Do NOT make assumptions about unclear input
- Wait for clear confirmation before proceeding

## Language Change Detection & Response
- **MONITOR**: Every user input for language changes
- **DETECT**: Use language patterns and keywords
- **RESPOND**: Immediately acknowledge language change
- **ADAPT**: Switch all subsequent responses to new language
- **MAINTAIN**: Keep conversation in new language until user changes again

## Product Information Accuracy
- Base recommendations on provided product specifications
- Do not invent features or specifications
- IF unsure about details, focus on confirmed features
- Always highlight key benefits relevant to customer needs
- Present information in culturally appropriate way

## Error Handling
- IF no suitable products match request: Politely explain limitations in current language
- IF technical issues occur: Apologize and offer alternative assistance
- IF customer seems frustrated: Acknowledge concerns and redirect positively
- Use culturally appropriate apologies and solutions

# Safety & Escalation
- Stay focused on appliance recommendations
- Do not provide advice outside product expertise
- IF customer has technical support needs: Acknowledge and suggest contacting technical support
- Maintain professional boundaries throughout interaction
- Respect cultural differences and preferences

# IMPORTANT REMINDERS
- NEVER include JSON data in your spoken responses
- NEVER mention "metadata", "JsonData", "ProductsCollection" in speech
- ALWAYS use the send_product_metadata tool for product data
- Keep spoken responses natural and conversational in current language
- The tool will handle sending structured data to the UI automatically
- ALWAYS maintain the language the user is currently using

# üéØ MULTIMEDIA & 3D TOOLS USAGE

## ÔøΩÔ∏è SHOW MULTIMEDIA TOOL
Use the \`show_multimedia\` tool when customers want to:
- See product videos
- View image galleries 
- See product photos/images
- Browse product carousel

**Usage Examples:**
- User: "Show me videos of this washer" ‚Üí Call: show_multimedia({"product_sku": "SWP500-FL", "content_type": "video"})
- User: "I want to see more images" ‚Üí Call: show_multimedia({"product_sku": "RF600-WH", "content_type": "gallery"})
- User: "Can you show me photos of the refrigerator?" ‚Üí Call: show_multimedia({"product_sku": "RF800-SS", "content_type": "images"})

**Content Types Available:**
- "video" - Product demonstration videos
- "gallery" - Image gallery view
- "images" - Product photos
- "carousel" - Sliding image carousel


Use the \`show_images\` tool when customers want to: 
- See product photos/images

**Usage Examples:**
- User: "Show me images of this washer" ‚Üí Call: show_images({"product_sku": "SWP500-FL", "content_type": "video"})
- User: "I want to see more images" ‚Üí Call: show_images({"product_sku": "RF600-WH", "content_type": "gallery"})
- User: "Can you show me photos of the refrigerator?" ‚Üí Call: show_images({"product_sku": "RF800-SS", "content_type": "images"})
- User: "Can you go back to image please?" ‚Üí Call: show_images({"product_sku": "RF800-SS", "content_type": "images"})

Use the \`show_video\` tool when customers want to: 
- See product photos/images

**Usage Examples:**
- User: "Show me a video of this product " ‚Üí Call: show_video({"product_sku": "SWP500-FL", "content_type": "video"})
- User: "I want to see a video" ‚Üí Call: show_video({"product_sku": "RF600-WH", "content_type": "gallery"})
- User: "Can you show me a video of the product?" ‚Üí Call: show_video({"product_sku": "RF800-SS", "content_type": "images"})
- User: "Can you go back to video please?" ‚Üí Call: show_video({"product_sku": "RF800-SS", "content_type": "images"})


## üéÆ SHOW 3D TOOL
Use the \`show_3d\` tool when customers want to:
- See 3D models of products
- View products in 360 degrees
- Interact with 3D visualizations
- **NOTE**: DO NOT use this for AR requests - use show_ar instead

**Usage Examples:**
- User: "Show me this in 3D" ‚Üí Call: show_3d({"product_sku": "ECO200-FL", "view_type": "3d-model"})
- User: "Can I see a 360 view?" ‚Üí Call: show_3d({"product_sku": "SWP300-TL", "view_type": "360-view"})

**View Types Available:**
- "3d-model" - Interactive 3D model
- "360-view" - 360-degree product view


## ‚ùå CLOSE CAROUSEL TOOL
Use the \`close_carousel\` tool when customers want to:
- Close the multimedia viewer
- Exit from images/video/3D/AR view
- Go back to the main conversation
- Stop viewing multimedia content
- Return to product selection

**Usage Examples:**
- User: "Close this" ‚Üí Call: close_carousel()
- User: "Go back" ‚Üí Call: close_carousel()
- User: "Exit" ‚Üí Call: close_carousel()
- User: "Stop showing me this" ‚Üí Call: close_carousel()
- User: "Cierra esto" ‚Üí Call: close_carousel()
- User: "Volver" ‚Üí Call: close_carousel()

**Natural Response Examples:**
- "Sure! I've closed the viewer for you."
- "Done! Going back to our conversation."
- "No problem! Viewer closed."

**IMPORTANT**: This tool requires NO parameters - just call close_carousel() directly.


## üéØ TOOL USAGE WORKFLOW
1. **Listen for multimedia/3D/AR/video/images/close requests**
2. **Identify the specific product SKU** (from previous recommendations - if needed)
3. **Choose appropriate tool based on user keywords**:
   - show_multimedia ‚Üí General multimedia content
   - show_3d ‚Üí Keywords: "3D", "360", "rotate", "spin"
   - show_ar ‚Üí Keywords: "AR", "my space", "my room", "augmented reality", "in my home", "in my house"
   - show_video ‚Üí Keywords: "video", "watch", "demonstration"
   - show_images ‚Üí Keywords: "images", "photos", "pictures", "gallery"
   - close_carousel ‚Üí Keywords: "close", "exit", "go back", "stop", "return"
4. **Call the tool with correct parameters**
5. **Give natural spoken confirmation** in current language

**Natural Response Examples:**
- "Perfect! Let me show you this in AR so you can see it in your space."
- "Great! Let me show you the 3D model right away."
- "Sure! Here are the product images."

## üö® MULTIMEDIA/3D/AR TOOL RULES:
- **ALWAYS use exact product SKUs** from catalog
- **Match tool to user keywords**:
  - "in my space/room/home" ‚Üí MUST use show_ar
  - "AR/augmented reality" ‚Üí MUST use show_ar
  - "3D/360" ‚Üí use show_3d
  - "video" ‚Üí use show_video
  - "images/photos" ‚Üí use show_images
- **CRITICAL**: Do NOT confuse AR with 3D - they are separate tools!
- **Provide spoken confirmation** after calling tool
- **Use tools when appropriate** - don't force if not requested
- **Complement product recommendations** with multimedia options

# ÔøΩüö® CRITICAL FINAL REMINDER üö®
EVERY TIME you recommend a product, you MUST:
1. Speak naturally about the product IN THE CURRENT LANGUAGE
2. Call send_product_metadata tool with complete data
3. NEVER skip the tool call - it's required for the UI to show product cards
4. NEVER change language unless user explicitly does so

ADDITIONALLY, when users request multimedia, 3D, AR, videos, or images:
1. Call the appropriate tool based on user keywords
2. Use the correct product SKU from previous recommendations
3. Give natural spoken confirmation in current language

**CRITICAL TOOL SELECTION**:
- User says "in my space/room" ‚Üí show_ar (NOT show_3d!)
- User says "AR/augmented reality" ‚Üí show_ar (NOT show_3d!)
- User says "3D/360/rotate" ‚Üí show_3d
- User says "video" ‚Üí show_video
- User says "images/photos" ‚Üí show_images

If you recommend a product but don't call the tool, the user won't see the product information visually, which breaks the experience.

ALWAYS CALL THE APPROPRIATE TOOLS WHEN NEEDED!
ALWAYS RESPOND IN THE USER'S CURRENT LANGUAGE!
NEVER CHANGE LANGUAGE UNLESS USER CHANGES FIRST!

## üéØ CONTEXTUAL DISCOVERY QUESTIONS

When a user shows interest in a product category, ALWAYS ask 2-3 relevant qualifying questions BEFORE making recommendations. This ensures personalized suggestions that truly match their needs.

### üìã QUESTION FRAMEWORK BY PRODUCT CATEGORY:

#### üßä REFRIGERATORS (RF600-WH, RF800-SS)
**ALWAYS ask these questions when user mentions refrigerator/fridge/nevera:**
1. **Budget & Size**: "What's your maximum budget, and how much space do you have available?"
2. **Household Size**: "How many people live in your home?"
3. **Key Features**: "Do you need specific features like water dispenser, ice maker, or dual cooling zones?"

**Example Flow:**
- User: "I need a refrigerator"
- Assistant: "Great! To help you find the perfect refrigerator, I'd like to know: What's your maximum budget? How many people are in your household? And how much space do you have available for the fridge?"

#### üß∫ WASHING MACHINES (ECO200-FL, SWP300-TL, SWP500-FL)
**ALWAYS ask these questions when user mentions washer/washing machine/lavadora:**
1. **Load Capacity**: "How much laundry do you typically wash per week? Do you need a large capacity or is something compact better?"
2. **Space Available**: "What's the space you have available? Are you looking for a front-load or top-load model?"
3. **Budget & Features**: "What's your budget range? Do you need specific features like quick wash, steam cleaning, or smart connectivity?"

**Example Flow:**
- User: "I want a washing machine"
- Assistant: "Perfect! Let me help you choose the ideal washer. Tell me: How much space do you have available? How many people are in your home? And what's your budget range?"

#### üè† GENERAL APPLIANCES
**For any appliance category, prioritize these questions:**
1. **Primary Need**: "What's your main priority - price, capacity, energy efficiency, or specific features?"
2. **Space & Installation**: "Where will you place this appliance? Do you have space constraints?"
3. **Budget Range**: "What's your budget range so I can show you the best options within your price point?"

### üé® QUESTION DELIVERY GUIDELINES:

**DO:**
- ‚úÖ Ask 2-3 questions maximum at once (don't overwhelm)
- ‚úÖ Combine related questions naturally
- ‚úÖ Use conversational, friendly language
- ‚úÖ Adapt questions to the user's language (ES/EN/FR)
- ‚úÖ Listen carefully to their answers before recommending

**DON'T:**
- ‚ùå Recommend products before understanding needs
- ‚ùå Ask more than 3 questions at once
- ‚ùå Repeat questions if user already provided that information
- ‚ùå Use technical jargon in questions
- ‚ùå Make assumptions about their needs

### üìù MULTILINGUAL QUESTION EXAMPLES:

**Spanish:**
- "Para recomendarte la mejor opci√≥n, ¬øcu√°l es tu presupuesto m√°ximo? ¬øCu√°ntas personas viven en tu hogar? ¬øY qu√© espacio tienes disponible?"
- "Perfecto, ¬øbuscas algo compacto o de gran capacidad? ¬øTienes alguna caracter√≠stica espec√≠fica en mente?"

**English:**
- "To find you the perfect match, what's your maximum budget? How many people are in your household? And how much space do you have available?"
- "Great! Are you looking for something compact or full-size? Do you have any specific features in mind?"

**French:**
- "Pour vous recommander la meilleure option, quel est votre budget maximum? Combien de personnes vivent chez vous? Et quel espace avez-vous disponible?"
- "Parfait! Cherchez-vous quelque chose de compact ou de grande capacit√©? Avez-vous des fonctionnalit√©s sp√©cifiques en t√™te?"

### üîÑ ADAPTIVE QUESTIONING:

**If user provides partial information:**
- Fill in gaps with targeted follow-up questions
- Example: User says "I need a cheap washer" ‚Üí Ask about space and household size

**If user is vague:**
- Gently guide them with specific options
- Example: "Are you looking for something under $500 or do you have more flexibility?"

**If user knows exactly what they want:**
- Skip unnecessary questions
- Confirm key requirements and proceed with recommendation

### ‚ö° WORKFLOW SUMMARY:

1. **User shows interest** ‚Üí Ask 2-3 qualifying questions
2. **User answers** ‚Üí Acknowledge and confirm understanding
3. **Make recommendation** ‚Üí Based on their specific answers
4. **Call tool** ‚Üí send_product_metadata with personalized reasoning

**REMEMBER**: Quality questions lead to better recommendations. Take time to understand before suggesting products.

`;
  }

  /**
   * Get language-specific terms and examples
   */
  private getLanguageSpecificTerms(language: string): any {
    const terms: { [key: string]: any } = {
      es: {
        pronunciations: `- Pronounce "WiFi" as "wai-fai"
- Pronounce "SmartWash" as "smart-wash"
- Pronounce "kg" as "kilogramos"
- Pronounce "cu.ft" as "pies c√∫bicos"
- Pronounce "My kit AI" as "mai kit eiai"
`,
        examples: `### Example 1: Single Washer
User: "Necesito una lavadora para mi apartamento peque√±o"
**Step 1 - Speak:** "¬°Perfecto! Te recomiendo la EcoWash 200, es compacta y perfecta para apartamentos."
**Step 2 - Call Tool:** send_product_metadata({"product_skus": ["ECO200-FL"], "reasoning": "Lavadora compacta ideal para apartamentos peque√±os"})

### Example 2: Multiple Washers
User: "Quiero una lavadora pero no s√© cu√°l elegir"
**Step 1 - Speak:** "Te muestro las mejores opciones de lavadoras seg√∫n diferentes necesidades."
**Step 2 - Call Tool:** send_product_metadata({"product_skus": ["SWP500-FL", "SWP300-TL", "ECO200-FL"], "reasoning": "Variedad de lavadoras para diferentes necesidades y presupuestos"})`,
        selectionResponses: `### Examples:
- Read the example whit de user language's
- "Excelente elecci√≥n. Estoy a tu servicio para cualquier pregunta sobre este producto. ¬øQuieres que te lo muestre en 3D o en realidad aumentada?"`,
        clarificationPhrases: `"Disculpa, no pude escucharte bien. ¬øPodr√≠as repetir?"`,
      },
      en: {
        pronunciations: `- Pronounce "WiFi" as "wai-fai"
- Pronounce "SmartWash" as "smart-wash"
- Pronounce "kg" as "kilograms"
- Pronounce "cu.ft" as "cubic feet"`,
        examples: `### Example 1: Single Washer
User: "I need a washer for my small apartment"
**Step 1 - Speak:** "Perfect! I recommend the EcoWash 200, it's compact and perfect for apartments."
**Step 2 - Call Tool:** send_product_metadata({"product_skus": ["ECO200-FL"], "reasoning": "Compact washer ideal for small apartments"})

### Example 2: Multiple Washers
User: "I want a washer but don't know which one to choose"
**Step 1 - Speak:** "Let me show you the best washer options for different needs."
**Step 2 - Call Tool:** send_product_metadata({"product_skus": ["SWP500-FL", "SWP300-TL", "ECO200-FL"], "reasoning": "Variety of washers for different needs and budgets"})`,
        selectionResponses: `### Examples:
- "Excellent choice! The SmartWash Pro 500 is perfect for you. Here you can see more multimedia information."
- "Great! The EcoWash 200 is ideal. You'll love its efficiency."
- "Good decision! The CoolMax Pro 800 has great capacity. Enjoy exploring its features."`,
        clarificationPhrases: `"Sorry, I couldn't hear you clearly. Could you repeat that?"`,
      },
      fr: {
        pronunciations: `- Pronounce "WiFi" as "wai-fai"
- Pronounce "SmartWash" as "smart-wash"
- Pronounce "kg" as "kilogrammes"
- Pronounce "cu.ft" as "pieds cubes"`,
        examples: `### Example 1: Single Washer
User: "J'ai besoin d'une machine √† laver pour mon petit appartement"
**Step 1 - Speak:** "Parfait! Je recommande l'EcoWash 200, elle est compacte et parfaite pour les appartements."
**Step 2 - Call Tool:** send_product_metadata({"product_skus": ["ECO200-FL"], "reasoning": "Machine √† laver compacte id√©ale pour petits appartements"})`,
        selectionResponses: `### Examples:
- "Excellent choix! La SmartWash Pro 500 est parfaite pour vous. Voici plus d'informations multim√©dias."
- "G√©nial! L'EcoWash 200 est id√©ale. Vous allez adorer son efficacit√©."`,
        clarificationPhrases: `"D√©sol√©, je n'ai pas bien entendu. Pourriez-vous r√©p√©ter?"`,
      },
    };

    return terms[language] || terms.en;
  }

  /**
   * Establishes connection to OpenAI Realtime API
   * @param callbacks - Event callbacks for connection lifecycle
   * @returns Promise that resolves when connection is established
   */
  async connect(callbacks?: {
    onConnected?: () => void;
    onDisconnected?: () => void;
    onError?: (error: Error) => void;
    onMessage?: (message: any) => void;
    // üÜï NUEVOS CALLBACKS PARA TRANSCRIPCI√ìN
    onUserTranscription?: (transcript: string, isComplete: boolean) => void;
    onAgentTranscriptionDelta?: (messageId: string, delta: string) => void;
    onAgentTranscriptionComplete?: (
      messageId: string,
      fullTranscript: string
    ) => void;
    onMetadata?: (metadata: any) => void;
  }): Promise<void> {
    if (this.isConnecting) {
      throw new Error("Connection already in progress");
    }

    if (this.isConnected) {
      console.log("‚ö†Ô∏è Already connected to Realtime API");
      return;
    }

    try {
      this.isConnecting = true;
      this.connectionCallbacks = callbacks || {};

      console.log("üîÑ Initializing OpenAI Realtime session...");

      // Get fresh token from session service
      const apiKey = await SessionService.getSessionToken();

      if (!SessionService.validateToken(apiKey)) {
        throw new Error("Invalid API key received from session service");
      }

      // Create agent first
      const agent = this.createAgent();
      console.log("ü§ñ Agent created:", agent);

      // Create new session with agent

      //   const options: RealtimeSessionOptions = {
      //     apiKey: apiKey,
      //     transport: "webrtc",
      //     config: {
      //       audio: {
      //         input: {
      //           noiseReduction: {
      //             type: "near_field",
      //           },
      //           turnDetection: {
      //             type: "server_vad",
      //             threshold: 1,
      //             prefix_padding_ms: "300",
      //             silence_duration_ms: "600",
      //           },
      //         },
      //       },
      //     },
      //   };

      this.session = new RealtimeSession(agent);
      console.log("üìã Session created:", this.session);

      // Set up event listeners before connecting
      this.setupEventListeners();

      // Connect to OpenAI Realtime API
      console.log("üîÑ Connecting to OpenAI Realtime API...");

      try {
        await this.session.connect({
          apiKey: apiKey,
        });

        // üÜï HABILITAR TRANSCRIPCI√ìN DE AUDIO
        console.log("üé§ Enabling audio transcription...");

        // üîç DEBUG: Ver qu√© m√©todos est√°n disponibles
        console.log(
          "üîç Available session methods:",
          Object.getOwnPropertyNames(this.session)
        );
        console.log(
          "üîç Session prototype methods:",
          Object.getOwnPropertyNames(Object.getPrototypeOf(this.session))
        );

        if (
          typeof (this.session as any).inputAudioTranscriptionEnable ===
          "function"
        ) {
          await (this.session as any).inputAudioTranscriptionEnable();
          console.log("‚úÖ Audio transcription enabled");
        } else {
          console.warn("‚ö†Ô∏è inputAudioTranscriptionEnable method not found");
        }

        console.log("‚úÖ Successfully connected to OpenAI Realtime API");
      } catch (connectError) {
        console.error("üö´ Connection error details:", connectError);
        throw new Error(
          `Connection failed: ${
            connectError instanceof Error
              ? connectError.message
              : String(connectError)
          }`
        );
      }
    } catch (error) {
      this.isConnecting = false;
      this.isConnected = false;

      const errorMessage =
        error instanceof Error ? error.message : "Unknown error occurred";
      console.error(
        "‚ùå Failed to connect to OpenAI Realtime API:",
        errorMessage
      );

      // Trigger error callback
      if (this.connectionCallbacks.onError) {
        this.connectionCallbacks.onError(
          error instanceof Error ? error : new Error(errorMessage)
        );
      }

      throw error;
    }
  }

  /**
   * Disconnects from OpenAI Realtime API
   */
  async disconnect(): Promise<void> {
    if (!this.session || !this.isConnected) {
      console.log("‚ö†Ô∏è No active session to disconnect");
      return;
    }

    try {
      console.log("üîÑ Disconnecting from OpenAI Realtime API...");

      // Close the session using the close method
      if (typeof this.session.close === "function") {
        await this.session.close();
      } else {
        // Force cleanup if no close method
        console.warn(
          "‚ö†Ô∏è No close method found on session, cleaning up manually"
        );
      }

      this.session = null;
      this.isConnected = false;
      this.isConnecting = false;
      // üÜï Limpiar buffer de transcripciones
      this.agentTranscriptBuffer = {};
      this.deltaAccumulator = {};
      this.lastDeltaTime = 0;

      console.log("‚úÖ Successfully disconnected from OpenAI Realtime API");

      // Trigger disconnected callback
      if (this.connectionCallbacks.onDisconnected) {
        this.connectionCallbacks.onDisconnected();
      }
    } catch (error) {
      console.error("‚ùå Error during disconnection:", error);
      // Force cleanup even if disconnect fails
      this.session = null;
      this.isConnected = false;
      this.isConnecting = false;
      this.agentTranscriptBuffer = {};
      this.deltaAccumulator = {};
      this.lastDeltaTime = 0;
      throw error;
    }
  }

  /**
   * Interrupts the agent if it's currently speaking
   */
  interrupt(): void {
    if (!this.session || !this.isConnected) {
      console.warn("‚ö†Ô∏è Cannot interrupt: Not connected to Realtime API");
      return;
    }

    try {
      console.log("üõë Interrupting agent...");
      this.session.interrupt();
      console.log("‚úÖ Agent interrupted successfully");
    } catch (error) {
      console.error("‚ùå Error interrupting agent:", error);
    }
  }

  /**
   * Sends a text message through the realtime session
   * @param message - The message to send
   */
  async sendMessage(message: string): Promise<void> {
    if (!this.session || !this.isConnected) {
      throw new Error("Not connected to Realtime API. Call connect() first.");
    }

    try {
      console.log("üì§ Sending message:", message);

      // üõë INTERRUPT AGENT BEFORE SENDING NEW MESSAGE
      this.interrupt();

      this.session.sendMessage(message);
    } catch (error) {
      console.error("‚ùå Error sending message:", error);
      throw error;
    }
  }

  /**
   * Sets up event listeners for the realtime session
   * @private
   */
  private setupEventListeners(): void {
    if (!this.session) return;

    try {
      // Use type assertion to work with the session events
      const session = this.session as any;

      // Manejar eventos del transport si existe
      if (session.transport && typeof session.transport.on === "function") {
        session.transport.on("*", (event: any) => {
          if (event.type == "session.created") {
            console.log("‚úÖ Transport session created:", event);
            this.isConnected = true;
            this.isConnecting = false;

            // Trigger connected callback
            if (this.connectionCallbacks.onConnected) {
              this.connectionCallbacks.onConnected();
            }
          }
          // üÜï CAPTURAR EVENTOS DE TRANSCRIPCI√ìN EN EL TRANSPORT
          else if (
            event.type === "conversation.item.input_audio_transcription.delta"
          ) {
            console.log("üìù USER TRANSCRIPTION DELTA (TRANSPORT):", event);
            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(event.delta, false);
            }
          } else if (
            event.type ===
            "conversation.item.input_audio_transcription.completed"
          ) {
            console.log("üìù USER TRANSCRIPTION COMPLETED (TRANSPORT):", event);
            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(
                event.transcript,
                true
              );
            }
          } else if (event.type === "response.output_audio_transcript.delta") {
            console.log("ü§ñ AGENT TRANSCRIPT DELTA (TRANSPORT):", event.delta);

            const responseId = event.response_id || "default";

            // üÜï ACUMULAR DELTAS PARA ENVIAR EN LOTES
            if (!this.deltaAccumulator[responseId]) {
              this.deltaAccumulator[responseId] = "";
            }
            this.deltaAccumulator[responseId] += event.delta;

            // Buffer para el transcript completo
            if (!this.agentTranscriptBuffer[responseId]) {
              this.agentTranscriptBuffer[responseId] = "";
            }
            this.agentTranscriptBuffer[responseId] += event.delta;

            // üÜï ENVIAR DELTAS ACUMULADOS CON THROTTLE
            const now = Date.now();
            if (now - this.lastDeltaTime >= this.deltaThrottle) {
              this.lastDeltaTime = now;

              if (this.connectionCallbacks.onAgentTranscriptionDelta) {
                // üÜï ENVIAR TODO EL TEXTO ACUMULADO HASTA AHORA
                this.connectionCallbacks.onAgentTranscriptionDelta(
                  responseId,
                  this.agentTranscriptBuffer[responseId]
                );
              }

              // NO limpiar acumulador, solo resetear para el pr√≥ximo lote
              this.deltaAccumulator[responseId] = "";
            }
          } else if (event.type === "response.output_audio_transcript.done") {
            console.log("ü§ñ AGENT TRANSCRIPT DONE (TRANSPORT):", event);

            const responseId = event.response_id || "default";
            const fullTranscript =
              event.transcript || this.agentTranscriptBuffer[responseId] || "";

            // üÜï ENVIAR √öLTIMOS DELTAS ACUMULADOS ANTES DE COMPLETAR
            if (
              this.deltaAccumulator[responseId] &&
              this.connectionCallbacks.onAgentTranscriptionDelta
            ) {
              // Enviar el texto completo final
              this.connectionCallbacks.onAgentTranscriptionDelta(
                responseId,
                this.agentTranscriptBuffer[responseId]
              );
            }

            if (this.connectionCallbacks.onAgentTranscriptionComplete) {
              this.connectionCallbacks.onAgentTranscriptionComplete(
                responseId,
                fullTranscript
              );
            }

            // Limpiar buffers
            delete this.agentTranscriptBuffer[responseId];
            delete this.deltaAccumulator[responseId];
          } else {
            console.log("Transport session event:", event.type);
          }
        });
      }

      if (typeof session.addListener === "function") {
        // üîç USAR LOS EVENTOS REALES QUE EST√ÅN LLEGANDO
        console.log("üîç Setting up REAL transcription events...");

        // üé§ EVENTOS DEL USUARIO (REALES)
        session.addListener(
          "input_audio_buffer.speech_started",
          (event: any) => {
            console.log("üé§ USER STARTED SPEAKING (REAL):", event);
          }
        );

        session.addListener(
          "input_audio_buffer.speech_stopped",
          (event: any) => {
            console.log("üé§ USER STOPPED SPEAKING (REAL):", event);
          }
        );

        session.addListener("input_audio_buffer.committed", (event: any) => {
          console.log("üé§ AUDIO BUFFER COMMITTED (REAL):", event);
        });

        // üìù TRANSCRIPCI√ìN DEL USUARIO EN TIEMPO REAL (CORRECTO)
        session.addListener(
          "conversation.item.input_audio_transcription.delta",
          (event: any) => {
            console.log("üìù USER TRANSCRIPTION DELTA (REAL):", event);
            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(event.delta, false);
            }
          }
        );

        session.addListener(
          "conversation.item.input_audio_transcription.completed",
          (event: any) => {
            console.log("üìù USER TRANSCRIPTION COMPLETED (REAL):", event);

            // üåç DETECT LANGUAGE CHANGE FROM USER INPUT
            if (event.transcript) {
              this.detectAndUpdateLanguage(event.transcript);
            }

            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(
                event.transcript,
                true
              );
            }
          }
        );

        // ü§ñ EVENTOS DEL AGENTE (REALES)
        session.addListener("response.created", (event: any) => {
          console.log("ü§ñ RESPONSE CREATED (REAL):", event);
        });

        session.addListener("response.output_item.added", (event: any) => {
          console.log("ü§ñ OUTPUT ITEM ADDED (REAL):", event);
        });

        session.addListener("response.content_part.added", (event: any) => {
          console.log("ü§ñ CONTENT PART ADDED (REAL):", event);
        });

        // ü§ñ TRANSCRIPCI√ìN DEL AGENTE EN TIEMPO REAL (CORRECTO)
        session.addListener(
          "response.output_audio_transcript.delta",
          (event: any) => {
            console.log("ü§ñ AGENT TRANSCRIPT DELTA (REAL):", event);

            const responseId = event.response_id || "default";

            if (!this.agentTranscriptBuffer[responseId]) {
              this.agentTranscriptBuffer[responseId] = "";
            }
            this.agentTranscriptBuffer[responseId] += event.delta;

            if (this.connectionCallbacks.onAgentTranscriptionDelta) {
              this.connectionCallbacks.onAgentTranscriptionDelta(
                responseId,
                event.delta
              );
            }
          }
        );

        session.addListener(
          "response.output_audio_transcript.done",
          (event: any) => {
            console.log("ü§ñ AGENT TRANSCRIPT DONE (REAL):", event);

            const responseId = event.response_id || "default";
            const fullTranscript =
              event.transcript || this.agentTranscriptBuffer[responseId] || "";

            if (this.connectionCallbacks.onAgentTranscriptionComplete) {
              this.connectionCallbacks.onAgentTranscriptionComplete(
                responseId,
                fullTranscript
              );
            }

            delete this.agentTranscriptBuffer[responseId];
          }
        );

        session.addListener("response.done", (event: any) => {
          console.log("ü§ñ RESPONSE DONE (REAL):", event);
        });

        // üõ†Ô∏è EVENTOS DE TOOL CALLS
        session.addListener(
          "response.function_call_arguments.delta",
          (event: any) => {
            console.log("üõ†Ô∏è TOOL CALL ARGUMENTS DELTA:", event);
          }
        );

        session.addListener(
          "response.function_call_arguments.done",
          (event: any) => {
            console.log("üõ†Ô∏è TOOL CALL ARGUMENTS DONE:", event);
          }
        );

        session.addListener("response.output_item.added", (event: any) => {
          console.log("üõ†Ô∏è OUTPUT ITEM ADDED:", event);

          // Verificar si es una llamada a funci√≥n
          if (event.item && event.item.type === "function_call") {
            console.log("üõ†Ô∏è Function call detected:", event.item);

            // Si es el tool send_product_metadata, procesarlo
            if (event.item.name === "send_product_metadata") {
              console.log("üõ†Ô∏è send_product_metadata tool call detected");
            }
          }
        });

        // üõ†Ô∏è LISTENER ESPEC√çFICO PARA TOOL CALLS COMPLETADOS
        session.addListener("conversation.item.created", (event: any) => {
          console.log("üõ†Ô∏è CONVERSATION ITEM CREATED:", event);

          if (event.item && event.item.type === "function_call") {
            console.log("üõ†Ô∏è Function call item created:", event.item);
            console.log("üõ†Ô∏è Function call name:", event.item.name);
            console.log(
              "üõ†Ô∏è Function call arguments (raw):",
              event.item.arguments
            );
            console.log("üõ†Ô∏è Arguments type:", typeof event.item.arguments);

            if (
              event.item.name === "send_product_metadata" &&
              event.item.arguments
            ) {
              try {
                let args;
                if (typeof event.item.arguments === "string") {
                  console.log(
                    "üõ†Ô∏è Parsing string arguments:",
                    event.item.arguments
                  );
                  args = JSON.parse(event.item.arguments);
                } else {
                  console.log("üõ†Ô∏è Using object arguments directly");
                  args = event.item.arguments;
                }

                console.log("üõ†Ô∏è Parsed args:", args);
                console.log("üõ†Ô∏è Args keys:", Object.keys(args || {}));

                // Formatear los datos correctamente
                const formattedMetadata = {
                  JsonData: {
                    jsonType: args.jsonType || "ProductsCollection",
                    products: args.products || [],
                  },
                  TextMessage:
                    "Aqu√≠ tienes algunos productos que podr√≠an interesarte:",
                };

                console.log(
                  "üõ†Ô∏è Sending formatted metadata from event listener:",
                  formattedMetadata
                );

                // Ejecutar el callback de metadata directamente
                if (this.connectionCallbacks.onMetadata) {
                  this.connectionCallbacks.onMetadata(formattedMetadata);
                }
              } catch (error) {
                console.error("üõ†Ô∏è Error processing tool arguments:", error);
                console.error(
                  "üõ†Ô∏è Raw arguments that failed:",
                  event.item.arguments
                );
              }
            }
          }
        });

        // Conversation item completed (sin parsing de metadata)
        session.addListener("conversation.item.completed", (event: any) => {
          console.log("‚úÖ CONVERSATION ITEM COMPLETED:", event);

          // Solo triggear el callback general (mantener compatibilidad)
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(event);
          }
        });

        // Evento de sesi√≥n creada
        session.addListener("session.created", (event: any) => {
          console.log("‚úÖ Session created successfully:", event);
        });

        // Eventos b√°sicos para compatibilidad
        session.addListener("item", (item: any) => {
          console.log("üì® Received item:", item);
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(item);
          }
        });

        session.addListener("error", (error: any) => {
          console.error("‚ùå Realtime session error:", error);
          if (this.connectionCallbacks.onError) {
            this.connectionCallbacks.onError(error);
          }
        });

        session.addListener("close", () => {
          console.log("üîå Realtime session closed");
          this.isConnected = false;
          if (this.connectionCallbacks.onDisconnected) {
            this.connectionCallbacks.onDisconnected();
          }
        });

        session.addListener("response", (response: any) => {
          console.log("üéØ Received response:", response);
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(response);
          }
        });

        session.addListener("item", (item: any) => {
          console.log("üì® Received item:", item);
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(item);
          }
        });

        session.addListener("error", (error: any) => {
          console.error("‚ùå Realtime session error:", error);
          if (this.connectionCallbacks.onError) {
            this.connectionCallbacks.onError(error);
          }
        });

        session.addListener("close", () => {
          console.log("üîå Realtime session closed");
          this.isConnected = false;
          if (this.connectionCallbacks.onDisconnected) {
            this.connectionCallbacks.onDisconnected();
          }
        });

        // Listen for response events
        session.addListener("response", (response: any) => {
          console.log("üéØ Received response:", response);
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(response);
          }
        });

        // üÜï NUEVOS EVENTOS PARA TRANSCRIPCI√ìN

        // Transcripci√≥n del usuario completada
        session.addListener(
          "conversation.item.input_audio_transcription.completed",
          (event: any) => {
            console.log("üìù User transcription:", event.transcript);

            // üåç DETECT LANGUAGE CHANGE FROM USER INPUT
            if (event.transcript) {
              this.detectAndUpdateLanguage(event.transcript);
            }

            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(
                event.transcript,
                true
              );
            }
          }
        );

        // Transcripci√≥n del agente en tiempo real (streaming)
        session.addListener("response.audio_transcript.delta", (event: any) => {
          console.log("ü§ñ Agent transcript delta:", event.delta);

          const responseId = event.response_id || "default";

          // Acumular el delta en el buffer
          if (!this.agentTranscriptBuffer[responseId]) {
            this.agentTranscriptBuffer[responseId] = "";
          }
          this.agentTranscriptBuffer[responseId] += event.delta;

          // Trigger callback con el delta
          if (this.connectionCallbacks.onAgentTranscriptionDelta) {
            this.connectionCallbacks.onAgentTranscriptionDelta(
              responseId,
              event.delta
            );
          }
        });

        // Transcripci√≥n del agente completada
        session.addListener("response.audio_transcript.done", (event: any) => {
          console.log("ü§ñ Agent transcript completed:", event.transcript);

          const responseId = event.response_id || "default";
          const fullTranscript =
            event.transcript || this.agentTranscriptBuffer[responseId] || "";

          if (this.connectionCallbacks.onAgentTranscriptionComplete) {
            this.connectionCallbacks.onAgentTranscriptionComplete(
              responseId,
              fullTranscript
            );
          }

          // Limpiar el buffer
          delete this.agentTranscriptBuffer[responseId];
        });

        // Conversation item completed (sin parsing de metadata)
        session.addListener("conversation.item.completed", (event: any) => {
          console.log("‚úÖ Conversation item completed:", event);

          // Solo triggear el callback general (mantener compatibilidad)
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(event);
          }
        });

        console.log("üìù Event listeners setup completed WITH TRANSCRIPTION");
      } else if (typeof session.on === "function") {
        // Evento de sesi√≥n creada
        session.on("session.created", (event: any) => {
          console.log("‚úÖ Session created successfully:", event);
        });

        // Try the 'on' method as alternative
        session.on("item", (item: any) => {
          console.log("ÔøΩ Received item:", item);
          if (this.connectionCallbacks.onMessage) {
            this.connectionCallbacks.onMessage(item);
          }
        });

        session.on("error", (error: any) => {
          console.error("‚ùå Realtime session error:", error);

          if (this.connectionCallbacks.onError) {
            this.connectionCallbacks.onError(error);
          }
        });

        // üÜï EVENTOS DE TRANSCRIPCI√ìN CON 'on' method
        session.on(
          "conversation.item.input_audio_transcription.completed",
          (event: any) => {
            console.log("üìù User transcription:", event.transcript);

            // üåç DETECT LANGUAGE CHANGE FROM USER INPUT
            if (event.transcript) {
              this.detectAndUpdateLanguage(event.transcript);
            }

            if (this.connectionCallbacks.onUserTranscription) {
              this.connectionCallbacks.onUserTranscription(
                event.transcript,
                true
              );
            }
          }
        );

        session.on("response.audio_transcript.delta", (event: any) => {
          console.log("ü§ñ Agent transcript delta:", event.delta);
          const responseId = event.response_id || "default";

          if (!this.agentTranscriptBuffer[responseId]) {
            this.agentTranscriptBuffer[responseId] = "";
          }
          this.agentTranscriptBuffer[responseId] += event.delta;

          if (this.connectionCallbacks.onAgentTranscriptionDelta) {
            this.connectionCallbacks.onAgentTranscriptionDelta(
              responseId,
              event.delta
            );
          }
        });

        session.on("response.audio_transcript.done", (event: any) => {
          console.log("ü§ñ Agent transcript completed:", event.transcript);
          const responseId = event.response_id || "default";
          const fullTranscript =
            event.transcript || this.agentTranscriptBuffer[responseId] || "";

          if (this.connectionCallbacks.onAgentTranscriptionComplete) {
            this.connectionCallbacks.onAgentTranscriptionComplete(
              responseId,
              fullTranscript
            );
          }

          delete this.agentTranscriptBuffer[responseId];
        });

        // üõ†Ô∏è TOOL EVENTS CON 'on' METHOD
        session.on("conversation.item.created", (event: any) => {
          console.log("üõ†Ô∏è CONVERSATION ITEM CREATED (ON):", event);

          if (event.item && event.item.type === "function_call") {
            console.log("üõ†Ô∏è Function call item created (ON):", event.item);
            console.log("üõ†Ô∏è Function call name (ON):", event.item.name);
            console.log(
              "üõ†Ô∏è Function call arguments (ON, raw):",
              event.item.arguments
            );

            if (
              event.item.name === "send_product_metadata" &&
              event.item.arguments
            ) {
              try {
                let args;
                if (typeof event.item.arguments === "string") {
                  console.log(
                    "üõ†Ô∏è Parsing string arguments (ON):",
                    event.item.arguments
                  );
                  args = JSON.parse(event.item.arguments);
                } else {
                  console.log("üõ†Ô∏è Using object arguments directly (ON)");
                  args = event.item.arguments;
                }

                console.log("üõ†Ô∏è Parsed args (ON):", args);

                // Formatear los datos correctamente
                const formattedMetadata = {
                  JsonData: {
                    jsonType: args.jsonType || "ProductsCollection",
                    products: args.products || [],
                  },
                  TextMessage:
                    "Aqu√≠ tienes algunos productos que podr√≠an interesarte:",
                };

                console.log(
                  "üõ†Ô∏è Sending formatted metadata from ON event listener:",
                  formattedMetadata
                );

                // Ejecutar el callback de metadata directamente
                if (this.connectionCallbacks.onMetadata) {
                  this.connectionCallbacks.onMetadata(formattedMetadata);
                }
              } catch (error) {
                console.error(
                  "üõ†Ô∏è Error processing tool arguments (ON):",
                  error
                );
                console.error(
                  "üõ†Ô∏è Raw arguments that failed (ON):",
                  event.item.arguments
                );
              }
            }
          }
        });

        console.log(
          "üìù Event listeners setup with 'on' method WITH TRANSCRIPTION AND TOOLS"
        );
      } else {
        console.log("üìù Event listeners setup - no compatible method found");
      }
    } catch (error) {
      console.error("‚ùå Error setting up event listeners:", error);
    }
  }

  /**
   * Gets the current connection status
   */
  getConnectionStatus(): {
    isConnected: boolean;
    isConnecting: boolean;
    hasSession: boolean;
  } {
    return {
      isConnected: this.isConnected,
      isConnecting: this.isConnecting,
      hasSession: this.session !== null,
    };
  }

  /**
   * Gets the current session instance (for advanced usage)
   * @returns The current RealtimeSession or null
   */
  getSession(): RealtimeSession<any> | null {
    return this.session;
  }

  /**
   * Triggers the metadata callback (used by tools)
   * @param metadata - The metadata to send
   */
  triggerMetadataCallback(metadata: any): void {
    if (this.connectionCallbacks.onMetadata) {
      this.connectionCallbacks.onMetadata(metadata);
    }
  }

  muteInput(muted: boolean): boolean {
    if (this.session && this.session.muted !== null) {
      this.session.transport.mute(muted);
    }
    return this.session?.transport.muted || false;
  }

  getAudioInputMuted(): boolean {
    return this.session?.transport.muted || false;
  }

  /**
   * Update current language and regenerate agent if needed
   */
  updateLanguage(newLanguage: string): void {
    if (this.currentLanguage !== newLanguage) {
      console.log(
        `üåç Language changed from ${this.currentLanguage} to ${newLanguage}`
      );
      this.lastDetectedLanguage = this.currentLanguage;
      this.currentLanguage = newLanguage;

      // Update language store
      const languageStore = useLanguageStore.getState();
      languageStore.setUserPreferredLanguage(newLanguage as LanguageCode);

      // If connected, send language switch acknowledgment
      if (this.isConnected && this.session) {
        const switchMessage = getLanguageSwitchMessage(newLanguage);
        console.log(`üåç Sending language switch message: ${switchMessage}`);
        // Note: The agent will automatically adapt to the new language in subsequent responses
      }
    }
  }

  /**
   * Detect language from user input and update if changed
   */
  private detectAndUpdateLanguage(userInput: string): void {
    const detectedLanguage = detectLanguageFromText(userInput);

    if (detectedLanguage && detectedLanguage !== this.currentLanguage) {
      console.log(
        `üåç Language change detected in user input: ${this.currentLanguage} -> ${detectedLanguage}`
      );
      this.updateLanguage(detectedLanguage);
    }
  }

  /**
   * Enhanced sendMessage with language detection
   */
  async sendMessageWithLanguageDetection(message: string): Promise<void> {
    // Detect language change before sending
    this.detectAndUpdateLanguage(message);

    // Send the message normally
    await this.sendMessage(message);
  }

  /**
   * Get current language information
   */
  getLanguageInfo(): {
    current: string;
    browser: string;
    hasGreeted: boolean;
    lastDetected: string | null;
  } {
    return {
      current: this.currentLanguage,
      browser: this.browserLanguage,
      hasGreeted: this.hasGreeted,
      lastDetected: this.lastDetectedLanguage,
    };
  }

  /**
   * Set greeting status
   */
  setHasGreeted(greeted: boolean): void {
    this.hasGreeted = greeted;
  }

  /**
   * Get appropriate greeting for current language
   */
  getCurrentLanguageGreeting(): string {
    return getGreetingForLanguage(this.currentLanguage);
  }

  /**
   * Static method to interrupt the agent from anywhere in the app
   */
  static interrupt(): void {
    const instance = RealtimeService.getInstance();
    instance.interrupt();
  }
}

export default RealtimeService.getInstance();
